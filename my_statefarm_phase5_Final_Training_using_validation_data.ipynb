{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statefarm Data - Phase5 - Final Modeling Using Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing various models after removal of marginal quality data and using 14000 cases of pseudo labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "IMPORT_DIR = '/home/ubuntu/nbs'\n",
    "%cd $IMPORT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import daveutils\n",
    "from daveutils import *\n",
    "import davenet\n",
    "from davenet import *\n",
    "import my_cv_modeler\n",
    "from my_cv_modeler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/home/ubuntu/'\n",
    "DATA_HOME_DIR = ALL_DATA_DIR+'statefarm/'\n",
    "TRAIN_DIR = DATA_HOME_DIR+'train/'\n",
    "VALID_DIR = DATA_HOME_DIR+'valid/'\n",
    "SAMPLE_DIR = DATA_HOME_DIR+'sample/'\n",
    "MODELS_DIR = DATA_HOME_DIR+'models/'\n",
    "RESULTS_DIR = DATA_HOME_DIR+'results/'\n",
    "TEST_DIR = DATA_HOME_DIR+'test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and remove poor quality training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously Identified Data that is badly classified or multi-class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/home/ubuntu/'\n",
    "TRAIN_DIR = ALL_DATA_DIR+'statefarm/train' # yes, this still includes the pseudo labelled data\n",
    "VALID_DIR = ALL_DATA_DIR+'statefarm/valid' #nb Notice that I've gone back to the orginal directory here\n",
    "from shutil import copy\n",
    "#%cd $DATA_HOME_DIR\n",
    "def copyFromValidToTrain():  #bad_dir must not already exist\n",
    "    count = 0\n",
    "    g = glob(VALID_DIR+'/c?/*.jpg')\n",
    "    for filename in g:\n",
    "        #print(TRAIN_DIR+filename[28:])\n",
    "        copy(filename, TRAIN_DIR+filename[28:])\n",
    "        count+=1\n",
    "    print(count,\"items successfully copied from \",VALID_DIR,\"folder to: \",TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3827 items successfully copied from  /home/ubuntu/statefarm/valid folder to:  /home/ubuntu/statefarm/train\n"
     ]
    }
   ],
   "source": [
    "copyFromValidToTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reload our previous best Sequential Vgg16 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = Dave16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 layers are frozen\n"
     ]
    }
   ],
   "source": [
    "model = vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]\n",
    "count_frozen = 0\n",
    "for layer in conv_layers:\n",
    "    layer.trainable = False\n",
    "    if layer.trainable == False: count_frozen+=1\n",
    "print(count_frozen,\"layers are frozen\")  \n",
    "conv_model = Sequential(conv_layers)\n",
    "top_hat_model = read_model(4, cross='old') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_bn_layers(p, model):\n",
    "    new_model = model\n",
    "    new_model.add(MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]))\n",
    "    new_model.add(Flatten())\n",
    "    new_model.add(Dropout(p/2))\n",
    "    new_model.add(Dense(128, activation='relu'))\n",
    "    #new_model.layers[len(new_model.layers)].set_weights(top.layers[3].get_weights())\n",
    "    new_model.add(BatchNormalization())\n",
    "    new_model.add(Dropout(p/2))\n",
    "    new_model.add(Dense(128, activation='relu'))\n",
    "    #new_model.layers[len(new_model.layers)].set_weights(top.layers[6].get_weights())\n",
    "    new_model.add(BatchNormalization())\n",
    "    new_model.add(Dropout(p))\n",
    "    new_model.add(Dense(10, activation='softmax'))  \n",
    "    #new_model.layers[len(new_model.layers)].set_weights(top.layers[9].get_weights())\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = add_bn_layers(0.5, conv_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.layers[last_conv_idx+3+1].set_weights(top_hat_model.layers[3].get_weights())\n",
    "full_model.layers[last_conv_idx+6+1].set_weights(top_hat_model.layers[6].get_weights())\n",
    "full_model.layers[last_conv_idx+9+1].set_weights(top_hat_model.layers[9].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_model.load_weights('/home/ubuntu/statefarm/cache/model_weights1vgg_minus_val.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model - including use of 14k pseudo label test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n.b. Mixiterator was not used.  Only test data having a prediction probability >0.995 has been used.\n",
    "This data is considered to be of such good quality that it can be mixed with real data. The pseudo training data will make up 43% of the training data at this stage (39% after validation data is added). Yes, it's a little high, but lets see how it goes.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the image generator (no augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3827 images belonging to 10 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3827"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator = gen.flow_from_directory(\n",
    "        'valid',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "val_generator.N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36648 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "dgen = ImageDataGenerator(  rotation_range=5,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.05,\n",
    "                            channel_shift_range = 20\n",
    "                         )\n",
    "tgenerator = dgen.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36648/36648 [==============================] - 955s - loss: 0.1099 - acc: 0.9719 - val_loss: 0.3268 - val_acc: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72c7fbf3d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.optimizer.lr=0.00005\n",
    "full_model.fit_generator(\n",
    "        tgenerator,\n",
    "        samples_per_epoch=tgenerator.N,\n",
    "        nb_epoch=1,\n",
    "        validation_data=val_generator,\n",
    "        nb_val_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, 1, cross='vgg16final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36648/36648 [==============================] - 1039s - loss: 0.0729 - acc: 0.9784 - val_loss: 0.1808 - val_acc: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72c7bb9910>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.optimizer.lr=0.00001\n",
    "full_model.fit_generator(\n",
    "        tgenerator,\n",
    "        samples_per_epoch=tgenerator.N,\n",
    "        nb_epoch=1,\n",
    "        validation_data=val_generator,\n",
    "        nb_val_samples=val_generator.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, 2, cross='vgg16final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36648/36648 [==============================] - 1041s - loss: 0.0581 - acc: 0.9820 - val_loss: 0.1180 - val_acc: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72c7bbaed0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.optimizer.lr=0.00001\n",
    "full_model.fit_generator(\n",
    "        tgenerator,\n",
    "        samples_per_epoch=tgenerator.N,\n",
    "        nb_epoch=1,\n",
    "        validation_data=val_generator,\n",
    "        nb_val_samples=val_generator.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, 3, cross='vgg16final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36648/36648 [==============================] - 1039s - loss: 0.0525 - acc: 0.9843 - val_loss: 0.0936 - val_acc: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72c7bbd690>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.optimizer.lr=0.00001\n",
    "full_model.fit_generator(\n",
    "        tgenerator,\n",
    "        samples_per_epoch=tgenerator.N,\n",
    "        nb_epoch=1,\n",
    "        validation_data=val_generator,\n",
    "        nb_val_samples=val_generator.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, 4, cross='vgg16final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the above validation dataset looks highly accurate, but do not be mislead, there same subject appear in the training dataset and validation dataset, albiet the versions in the training dataset are augmented.  \n",
    "\n",
    "Pose estimation is difficult when harnessing transfer learning from Vgg16 (or Vgg19) because different poses were not different classes in the original Vgg modeles, nor were hands, hands holding cups, hand holding mobile phone down low, hands holding mobile phone up near ears. 22k images is hardly sufficient training data for classifying vastly similar poses in 224x224 images with vastly different test subjects; especially when bounding boxes are not provided; and especially when there are 10 different classes hence a random uniform guess at the actual class is only expected to be correct around 10% of the time, i.e. there is much bigger gap (to 100% c.c.r.) as compared to a two-class classifier.  \n",
    "\n",
    "The next logical step is to incorporate hand, steering wheel, face, phone, make-up mirror/gaze direction bounding boxes (or segmentation) into a multi-label neural network model to improve performance.  For example, a model  bounding boxes for hands could be trained on an annotated hand dataset (e.g. http://www.robots.ox.ac.uk/~vgg/data/hands/) then used to predict the bounding boxes for hands in the images of the distracted-driver data set.  Similarly, the bounding boxes for steering wheel, face, phone, make-up mirror and gaze direction (can just be a two points forming a vector from the estimated centre of the eyeball to the centre of the pupil). Using the functional model API of Keras, the outputs of the bounding boxes can be connected with regression activation function to the second last layer of the model for the classification output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
